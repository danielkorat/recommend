{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, os, random, shutil, urllib.request, zipfile, time, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from functools import wraps\n",
    "from math import trunc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from scipy.sparse.linalg import norm\n",
    "import scipy.sparse as ss\n",
    "from scipy.sparse.linalg import svds\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import plotly.express as px\n",
    "\n",
    "SEED = 123\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mktkcXOFQrw"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lj_Na91f60Vw"
   },
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    path = Path(\"m1.zip\")\n",
    "    if not path.exists():\n",
    "        with path.open(\"wb\") as f:\n",
    "            print(\"Downloading dataset...\")\n",
    "            f.write(urlopen(\"http://files.grouplens.org/datasets/movielens/ml-1m.zip\").read())\n",
    "    if not Path(\"ml-1m\").is_dir():\n",
    "        print(\"unzipping...\")\n",
    "        with ZipFile(\"m1.zip\") as zf:\n",
    "            zf.extractall()\n",
    "    ratings_list = [i.strip().split(\"::\") for i in open('ml-1m/ratings.dat', 'r').readlines()]\n",
    "    ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = int)\n",
    "    ratings_df['Rating'] = ratings_df['Rating'].apply(pd.to_numeric)\n",
    "    return ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iI9441n7DltF"
   },
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    R_df = ratings_df.pivot(index = 'UserID', columns ='MovieID', values = 'Rating').fillna(0)\n",
    "    seed_everything()\n",
    "    test_indices = np.array(random.sample(list(np.argwhere(R_df.values>0)), 2500))\n",
    "\n",
    "    x_indices = test_indices[:,0]\n",
    "    y_indices = test_indices[:,1]\n",
    "    u_ids = R_df.index[x_indices].astype(np.int32)\n",
    "    i_ids = R_df.columns[y_indices].astype(np.int32)\n",
    "    \n",
    "    df['UserID'] = df['UserID'].astype(np.int32)\n",
    "    df['MovieID'] = df['MovieID'].astype(np.int32)\n",
    "    df['Rating'] = df['Rating'].astype(np.float64)\n",
    "    \n",
    "    df= df.drop(columns=['Timestamp'], errors='ignore')\n",
    "    \n",
    "    test = []\n",
    "    for u_id, i_id in zip(u_ids, i_ids):\n",
    "        test.append(df.loc[(df['UserID'] == u_id) & (df['MovieID'] == i_id)])\n",
    "    test_df = pd.concat(test)\n",
    "    train_df= df.drop(test_df.index.tolist())\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "-6PSReAzrbvQ",
    "outputId": "539848f5-c47e-4a7d-8558-02545f03bbc0"
   },
   "outputs": [],
   "source": [
    "ratings_df = get_dataset()\n",
    "train_df, test_df = split(ratings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQh7Ixoyycky"
   },
   "source": [
    "# Funk-SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shuffle(X):\n",
    "    np.random.shuffle(X)\n",
    "    return X\n",
    "\n",
    "def _initialization(n_users, n_items, n_factors):\n",
    "    bu = np.zeros(n_users)\n",
    "    bi = np.zeros(n_items)\n",
    "    pu = np.random.normal(0, .1, (n_users, n_factors))\n",
    "    qi = np.random.normal(0, .1, (n_items, n_factors))\n",
    "    return bu, bi, pu, qi\n",
    "\n",
    "def _run_epoch(X, bu, bi, pu, qi, global_mean, n_factors, lr, reg):\n",
    "    for i in range(X.shape[0]):\n",
    "        user, item, rating = int(X[i, 0]), int(X[i, 1]), X[i, 2]\n",
    "\n",
    "        # Predict current rating\n",
    "        pred = global_mean + bu[user] + bi[item]\n",
    "\n",
    "        for factor in range(n_factors):\n",
    "            pred += pu[user, factor] * qi[item, factor]\n",
    "        err = rating - pred\n",
    "\n",
    "        # Update biases\n",
    "        bu[user] += lr * (err - reg * bu[user])\n",
    "        bi[item] += lr * (err - reg * bi[item])\n",
    "\n",
    "        # Update latent factors\n",
    "        for factor in range(n_factors):\n",
    "            puf = pu[user, factor]\n",
    "            qif = qi[item, factor]\n",
    "            pu[user, factor] += lr * (err * qif - reg * puf)\n",
    "            qi[item, factor] += lr * (err * puf - reg * qif)\n",
    "    return bu, bi, pu, qi\n",
    "\n",
    "def _compute_metrics(X_val, bu, bi, pu, qi, global_mean, n_factors):\n",
    "    residuals = []\n",
    "    for i in range(X_val.shape[0]):\n",
    "        user, item, rating = int(X_val[i, 0]), int(X_val[i, 1]), X_val[i, 2]\n",
    "        pred = global_mean\n",
    "        if user > -1:\n",
    "            pred += bu[user]\n",
    "        if item > -1:\n",
    "            pred += bi[item]\n",
    "        if (user > -1) and (item > -1):\n",
    "            for factor in range(n_factors):\n",
    "                pred += pu[user, factor] * qi[item, factor]\n",
    "        residuals.append(rating - pred)\n",
    "    residuals = np.array(residuals)\n",
    "    loss = np.square(residuals).mean()\n",
    "    rmse = np.sqrt(loss)\n",
    "    mae = np.absolute(residuals).mean()\n",
    "    return loss, rmse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funk SVD Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    def __init__(self, lr=.005, reg=.02, n_epochs=20, n_factors=100,\n",
    "                 early_stopping=False, shuffle=False, min_delta=.001,\n",
    "                 min_rating=1, max_rating=5):\n",
    "\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "        self.n_epochs = n_epochs\n",
    "        self.n_factors = n_factors\n",
    "        self.early_stopping = early_stopping\n",
    "        self.shuffle = shuffle\n",
    "        self.min_delta = min_delta\n",
    "        self.min_rating = min_rating\n",
    "        self.max_rating = max_rating\n",
    "\n",
    "    def fit(self, X, X_val=None):\n",
    "        X = self._preprocess_data(X)\n",
    "        if X_val is not None:\n",
    "            X_val = self._preprocess_data(X_val, train=False, verbose=False)\n",
    "            self._init_metrics()\n",
    "        self.global_mean_ = np.mean(X[:, 2])\n",
    "        return self._run_sgd(X, X_val)\n",
    "\n",
    "    def _preprocess_data(self, X, train=True, verbose=True):\n",
    "        X = X.copy()\n",
    "\n",
    "        if train:  # Mappings have to be created\n",
    "            user_ids = X['UserID'].unique().tolist()\n",
    "            item_ids = X['MovieID'].unique().tolist()\n",
    "            n_users = len(user_ids)\n",
    "            n_items = len(item_ids)\n",
    "            user_idx = range(n_users)\n",
    "            item_idx = range(n_items)\n",
    "            self.user_mapping_ = dict(zip(user_ids, user_idx))\n",
    "            self.item_mapping_ = dict(zip(item_ids, item_idx))\n",
    "        X['UserID'] = X['UserID'].map(self.user_mapping_)\n",
    "        X['MovieID'] = X['MovieID'].map(self.item_mapping_)\n",
    "\n",
    "        # Tag validation set unknown users/items with -1 (enables\n",
    "        # `fast_methods._compute_val_metrics` detecting them)\n",
    "        X.fillna(-1, inplace=True)\n",
    "        \n",
    "        X['UserID'] = X['UserID'].astype(np.int32)\n",
    "        X['MovieID'] = X['MovieID'].astype(np.int32)\n",
    "        return X[['UserID', 'MovieID', 'Rating']].values\n",
    "\n",
    "    def _init_metrics(self):\n",
    "        metrics = np.zeros((self.n_epochs, 3), dtype=np.float)\n",
    "        self.metrics_ = pd.DataFrame(metrics, columns=['loss', 'RMSE', 'MAE'])\n",
    "\n",
    "    def _run_sgd(self, X, X_val):\n",
    "        n_users, n_items = len(np.unique(X[:, 0])), len(np.unique(X[:, 1]))\n",
    "        val_loss, val_rmse = '', ''\n",
    "        bu, bi, pu, qi = _initialization(n_users, n_items, self.n_factors)\n",
    "\n",
    "        # Run SGD\n",
    "        pbar = tqdm(range(self.n_epochs), desc='Epoch')\n",
    "        for epoch_ix in pbar:\n",
    "            bu, bi, pu, qi = \\\n",
    "                _run_epoch(X, bu, bi, pu, qi, self.global_mean_, self.n_factors, self.lr, self.reg)\n",
    "            \n",
    "            if X_val is not None:\n",
    "                self.metrics_.loc[epoch_ix, :] = _compute_metrics(\n",
    "                                                     X_val, bu, bi, pu, qi,\n",
    "                                                     self.global_mean_,\n",
    "                                                     self.n_factors)\n",
    "                f = lambda x: f\"{self.metrics_.loc[epoch_ix, x]:.3f}\"\n",
    "                pbar.set_postfix({f'val_{m}': f(m) for m in self.metrics_.columns})\n",
    "                if self._early_stopping(epoch_ix, self.min_delta):\n",
    "                    break\n",
    "\n",
    "        self.bu_, self.bi_, self.pu_, self.qi_ = bu, bi, pu, qi\n",
    "        \n",
    "        return {f\"val_{m}\": np.trim_zeros(self.metrics_[m]) for m in self.metrics_.columns}\n",
    "\n",
    "    def predict(self, X, clip=True):\n",
    "        return [self.predict_pair(u_id, i_id, clip)\\\n",
    "                for u_id, i_id in zip(X['UserID'], X['MovieID'])]\n",
    "\n",
    "    def predict_pair(self, u_id, i_id, clip=True):\n",
    "        user_known, item_known = False, False\n",
    "        pred = self.global_mean_\n",
    "\n",
    "        if u_id in self.user_mapping_:\n",
    "            user_known = True\n",
    "            u_ix = self.user_mapping_[u_id]\n",
    "            pred += self.bu_[u_ix]\n",
    "        if i_id in self.item_mapping_:\n",
    "            item_known = True\n",
    "            i_ix = self.item_mapping_[i_id]\n",
    "            pred += self.bi_[i_ix]\n",
    "        if user_known and item_known:\n",
    "            pred += np.dot(self.pu_[u_ix], self.qi_[i_ix])\n",
    "        if clip:\n",
    "            pred = self.max_rating if pred > self.max_rating else pred\n",
    "            pred = self.min_rating if pred < self.min_rating else pred\n",
    "        return pred\n",
    "\n",
    "    def _early_stopping(self, epoch_idx, min_delta):\n",
    "        val_rmse = self.metrics_['RMSE'].tolist()\n",
    "        if self.early_stopping and epoch_idx > 0:\n",
    "            if val_rmse[epoch_idx] + min_delta > val_rmse[epoch_idx-1]:\n",
    "                self.metrics_ = self.metrics_.loc[:(epoch_idx+1), :]\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "code",
    "id": "vfXchdoCr7Z5"
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return mse(y_true, y_pred, squared=False)\n",
    "\n",
    "def funk(train, test, **kw):\n",
    "    seed_everything()\n",
    "    svd = SVD(**kw)\n",
    "    hist = svd.fit(X=train, X_val=test)\n",
    "    y_true, y_pred = test['Rating'], svd.predict(test)\n",
    "    print(f\"Test RMSE: {rmse(y_true, y_pred):.4f}\\n\\n\")\n",
    "    print_hparams(kw)\n",
    "    return hist\n",
    "\n",
    "def print_hparams(h):\n",
    "    print(\"Hyperparameters:\\n\")\n",
    "    print(\"hist = funk(train_df, test_df,\\n\\t\" + \", \".join([f\"{k}={h[k]}\" for k in h]) + ')')\n",
    "    \n",
    "def plot_experiment(hist):\n",
    "    px.line(pd.DataFrame(hist).rename_axis('Epoch'))\\\n",
    "        .update_layout(hoverlabel=dict(font_size=12, font_family=\"Rockwell\"),\n",
    "                       font=dict(family=\"Courier New, monospace\", size=18))\\\n",
    "        .update_xaxes(showgrid=False, showspikes=True).show(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 1/2 [00:36<00:36, 36.82s/it, val_loss=0.846, val_RMSE=0.920, val_MAE=0.731]"
     ]
    }
   ],
   "source": [
    "hist = funk(train=train_df, test=test_df,\n",
    "\t\tearly_stopping=False,\n",
    "\t\tmin_delta=1e-05,\n",
    "\t\tlr=0.01,\n",
    "\t\treg=0.005,\n",
    "\t\tn_epochs=2,\n",
    "\t\tn_factors=15)\n",
    "    \n",
    "plot_experiment(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RMSE: 0.8643\n",
    "\n",
    "\n",
    "# Hyperparameters:\n",
    "\n",
    "# hist = funk(train_df, test_df,\n",
    "# \tearly_stopping=False, min_delta=1e-05, lr=0.01, reg=0.005, n_epochs=10, n_factors=15)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ex3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mf",
   "language": "python",
   "name": "mf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
