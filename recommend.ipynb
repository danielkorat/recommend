{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q -q -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, os, random, shutil, urllib.request, zipfile, time, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from functools import wraps\n",
    "from math import trunc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from scipy.sparse.linalg import norm\n",
    "import scipy.sparse as ss\n",
    "from scipy.sparse.linalg import svds\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import plotly.express as px\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "SEED = 123\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mktkcXOFQrw"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lj_Na91f60Vw"
   },
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    path = Path(\"m1.zip\")\n",
    "    if not path.exists():\n",
    "        with path.open(\"wb\") as f:\n",
    "            print(\"Downloading dataset...\")\n",
    "            f.write(urlopen(\"http://files.grouplens.org/datasets/movielens/ml-1m.zip\").read())\n",
    "    if not Path(\"ml-1m\").is_dir():\n",
    "        print(\"unzipping...\")\n",
    "        with ZipFile(\"m1.zip\") as zf:\n",
    "            zf.extractall()\n",
    "    ratings_list = [i.strip().split(\"::\") for i in open('ml-1m/ratings.dat', 'r').readlines()]\n",
    "    ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = int)\n",
    "    ratings_df['Rating'] = ratings_df['Rating'].apply(pd.to_numeric)\n",
    "    return ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iI9441n7DltF"
   },
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    R_df = ratings_df.pivot(index = 'UserID', columns ='MovieID', values = 'Rating').fillna(0)\n",
    "    seed_everything()\n",
    "    test_indices = np.array(random.sample(list(np.argwhere(R_df.values>0)), 2500))\n",
    "\n",
    "    x_indices = test_indices[:,0]\n",
    "    y_indices = test_indices[:,1]\n",
    "    u_ids = R_df.index[x_indices].astype(np.int32)\n",
    "    i_ids = R_df.columns[y_indices].astype(np.int32)\n",
    "    \n",
    "    df['UserID'] = df['UserID'].astype(np.int32)\n",
    "    df['MovieID'] = df['MovieID'].astype(np.int32)\n",
    "    df['Rating'] = df['Rating'].astype(np.float64)\n",
    "    \n",
    "    df= df.drop(columns=['Timestamp'], errors='ignore')\n",
    "    \n",
    "    test = []\n",
    "    for u_id, i_id in zip(u_ids, i_ids):\n",
    "        test.append(df.loc[(df['UserID'] == u_id) & (df['MovieID'] == i_id)])\n",
    "    test_df = pd.concat(test)\n",
    "    train_df= df.drop(test_df.index.tolist())\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "-6PSReAzrbvQ",
    "outputId": "539848f5-c47e-4a7d-8558-02545f03bbc0"
   },
   "outputs": [],
   "source": [
    "ratings_df = get_dataset()\n",
    "train_df, test_df = split(ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206405</th>\n",
       "      <td>1265</td>\n",
       "      <td>1732</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409183</th>\n",
       "      <td>2456</td>\n",
       "      <td>2105</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240650</th>\n",
       "      <td>1449</td>\n",
       "      <td>2959</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886005</th>\n",
       "      <td>5350</td>\n",
       "      <td>2640</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540360</th>\n",
       "      <td>3323</td>\n",
       "      <td>3468</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        UserID  MovieID  Rating\n",
       "206405    1265     1732     4.0\n",
       "409183    2456     2105     3.0\n",
       "240650    1449     2959     4.0\n",
       "886005    5350     2640     2.0\n",
       "540360    3323     3468     4.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQh7Ixoyycky"
   },
   "source": [
    "# Funk-SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@njit\n",
    "def _shuffle(X):\n",
    "    np.random.shuffle(X)\n",
    "    return X\n",
    "\n",
    "@njit\n",
    "def _initialization(n_users, n_items, n_factors):\n",
    "    bu = np.zeros(n_users)\n",
    "    bi = np.zeros(n_items)\n",
    "    pu = np.random.normal(0, .1, (n_users, n_factors))\n",
    "    qi = np.random.normal(0, .1, (n_items, n_factors))\n",
    "    return bu, bi, pu, qi\n",
    "\n",
    "@njit\n",
    "def _run_epoch(X, bu, bi, pu, qi, global_mean, n_factors, lr, reg):\n",
    "    for i in range(X.shape[0]):\n",
    "        user, item, rating = int(X[i, 0]), int(X[i, 1]), X[i, 2]\n",
    "\n",
    "        # Predict current rating\n",
    "        pred = global_mean + bu[user] + bi[item]\n",
    "\n",
    "        for factor in range(n_factors):\n",
    "            pred += pu[user, factor] * qi[item, factor]\n",
    "        err = rating - pred\n",
    "\n",
    "        # Update biases\n",
    "        bu[user] += lr * (err - reg * bu[user])\n",
    "        bi[item] += lr * (err - reg * bi[item])\n",
    "\n",
    "        # Update latent factors\n",
    "        for factor in range(n_factors):\n",
    "            puf = pu[user, factor]\n",
    "            qif = qi[item, factor]\n",
    "            pu[user, factor] += lr * (err * qif - reg * puf)\n",
    "            qi[item, factor] += lr * (err * puf - reg * qif)\n",
    "    return bu, bi, pu, qi\n",
    "\n",
    "@njit\n",
    "def _compute_val_metrics(X_val, bu, bi, pu, qi, global_mean, n_factors):\n",
    "    residuals = []\n",
    "    for i in range(X_val.shape[0]):\n",
    "        user, item, rating = int(X_val[i, 0]), int(X_val[i, 1]), X_val[i, 2]\n",
    "        pred = global_mean + bu[user] + bi[item]\n",
    "\n",
    "        for factor in range(n_factors):\n",
    "            pred += pu[user, factor] * qi[item, factor]\n",
    "        residuals.append(rating - pred)\n",
    "    residuals = np.array(residuals)\n",
    "    loss = np.square(residuals).mean()\n",
    "    rmse = np.sqrt(loss)\n",
    "    mae = np.absolute(residuals).mean()\n",
    "    return loss, rmse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funk SVD Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    def __init__(self, lr=.005, reg=.02, n_epochs=20, n_factors=100,\n",
    "                 min_delta=.001,\n",
    "                 min_rating=1, max_rating=5):\n",
    "\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "        self.n_epochs = n_epochs\n",
    "        self.n_factors = n_factors\n",
    "        self.min_rating = min_rating\n",
    "        self.max_rating = max_rating\n",
    "\n",
    "    def fit(self, X, X_test):\n",
    "        X = self._preprocess_data(X)\n",
    "\n",
    "        \n",
    "        X_test = self._preprocess_data(X_test, train=False)\n",
    "        self._init_metrics()\n",
    "        self.global_mean_ = np.mean(X[:, 2])\n",
    "        return self._run_sgd(X, X_test)\n",
    "\n",
    "    def _preprocess_data(self, X, train=True):\n",
    "        X = X.copy()\n",
    "\n",
    "        if train:  # Mappings have to be created\n",
    "            user_ids = X['UserID'].unique().tolist()\n",
    "            item_ids = X['MovieID'].unique().tolist()\n",
    "            n_users = len(user_ids)\n",
    "            n_items = len(item_ids)\n",
    "            user_idx = range(n_users)\n",
    "            item_idx = range(n_items)\n",
    "            self.user_mapping_ = dict(zip(user_ids, user_idx))\n",
    "            self.item_mapping_ = dict(zip(item_ids, item_idx))\n",
    "        X['UserID'] = X['UserID'].map(self.user_mapping_)\n",
    "        X['MovieID'] = X['MovieID'].map(self.item_mapping_)\n",
    "        \n",
    "        X['UserID'] = X['UserID'].astype(np.int32)\n",
    "        X['MovieID'] = X['MovieID'].astype(np.int32)\n",
    "        return X[['UserID', 'MovieID', 'Rating']].values\n",
    "\n",
    "    def _init_metrics(self):\n",
    "        metrics = np.zeros((self.n_epochs, 3), dtype=np.float)\n",
    "        self.metrics_ = pd.DataFrame(metrics, columns=['Loss', 'RMSE', 'MAE'])\n",
    "\n",
    "    def _run_sgd(self, X, X_test):\n",
    "        n_users = len(np.unique(X[:, 0]))\n",
    "        n_items = len(np.unique(X[:, 1]))\n",
    "        \n",
    "        bu, bi, pu, qi = _initialization(n_users, n_items, self.n_factors)\n",
    "\n",
    "        # Run SGD\n",
    "        pbar = tqdm(range(self.n_epochs), desc='Epoch',\n",
    "                             ncols=110)\n",
    "        for epoch_ix in pbar:\n",
    "            bu, bi, pu, qi = _run_epoch(X, bu, bi, pu, qi, self.global_mean_,\n",
    "                                        self.n_factors, self.lr, self.reg)\n",
    "\n",
    "            self.metrics_.loc[epoch_ix, :] = _compute_val_metrics(\n",
    "                                                 X_test, bu, bi, pu, qi,\n",
    "                                                 self.global_mean_,\n",
    "                                                 self.n_factors)\n",
    "            f = lambda x: f\"{self.metrics_.loc[epoch_ix, x]:.3f}\"\n",
    "            pbar.set_postfix({f'test_{m}': f(m) for m in self.metrics_.columns})\n",
    "\n",
    "        self.bu_,self.bi_,self.pu_,self.qi_ = bu, bi, pu, qi\n",
    "        return {f\"test_{m}\": np.trim_zeros(self.metrics_[m]) for m in self.metrics_.columns}\n",
    "\n",
    "    def predict(self, X, clip=True):\n",
    "        return [\n",
    "            self.predict_pair(u_id, i_id)\n",
    "            for u_id, i_id in zip(X['UserID'], X['MovieID'])\n",
    "        ]\n",
    "\n",
    "    def predict_pair(self, u_id, i_id):\n",
    "        assert u_id in self.user_mapping_ and i_id in self.item_mapping_, f\"user {u_id} or movie {i_id} not in train data\"\n",
    "        \n",
    "        if u_id in self.user_mapping_ and i_id in self.item_mapping_:\n",
    "            i_ix = self.item_mapping_[i_id]\n",
    "            u_ix = self.user_mapping_[u_id]\n",
    "            pred = self.global_mean_ + self.bi_[i_ix] +self.bu_[u_ix] + np.dot(self.pu_[u_ix], self.qi_[i_ix])\n",
    "        pred = np.clip(pred, self.min_rating, self.max_rating)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellView": "code",
    "id": "vfXchdoCr7Z5"
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return mse(y_true, y_pred, squared=False)\n",
    "\n",
    "def funk(train, test, **kw):\n",
    "    seed_everything()\n",
    "    svd = SVD(**kw)\n",
    "    hist = svd.fit(X=train, X_test=test)\n",
    "    y_true, y_pred = test['Rating'].values.ravel(), np.array(svd.predict(test)).ravel()\n",
    "    print(f\"Test RMSE: {rmse(y_true, y_pred):.4f}\\n\\n\")\n",
    "    print_hparams(kw)\n",
    "    return hist, svd\n",
    "\n",
    "def print_hparams(h):\n",
    "    print(\"Hyperparameters:\\n\")\n",
    "    print(\"hist = funk(train_df, test_df,\\n\\t\" + \", \".join([f\"{k}={h[k]}\" for k in h]) + ')')\n",
    "    \n",
    "def plot_experiment(hist):\n",
    "    fig = px.line(pd.DataFrame(hist).rename_axis('Epoch'))\\\n",
    "        .update_layout(hoverlabel=dict(font_size=12, font_family=\"Rockwell\"),\n",
    "                       font=dict(family=\"Courier New, monospace\", size=18))\\\n",
    "        .update_xaxes(showspikes=True)\n",
    "    fig.show(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████| 3/3 [00:02<00:00,  1.22it/s, test_Loss=0.825, test_RMSE=0.908, test_MAE=0.717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9083\n",
      "\n",
      "\n",
      "Hyperparameters:\n",
      "\n",
      "hist = funk(train_df, test_df,\n",
      "\tlr=0.01, reg=0.005, n_epochs=3, n_factors=15)\n"
     ]
    }
   ],
   "source": [
    "hist,svd = funk(train=train_df, test=test_df,\n",
    "\t\tlr=0.01,\n",
    "\t\treg=0.005,\n",
    "\t\tn_epochs=3,\n",
    "\t\tn_factors=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_experiment(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RMSE: 0.8643\n",
    "\n",
    "\n",
    "# Hyperparameters:\n",
    "\n",
    "# hist = funk(train_df, test_df,\n",
    "# \tearly_stopping=False, min_delta=1e-05, lr=0.01, reg=0.005, n_epochs=10, n_factors=15)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ex3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
