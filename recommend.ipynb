{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Downloading numba-0.52.0-cp37-cp37m-win_amd64.whl (2.3 MB)\n",
      "Collecting llvmlite<0.36,>=0.35.0\n",
      "  Downloading llvmlite-0.35.0-cp37-cp37m-win_amd64.whl (16.0 MB)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\iddo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from numba) (1.17.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\iddo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from numba) (41.2.0)\n",
      "Installing collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.35.0 numba-0.52.0\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install -U matplotlib\n",
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, os, random, shutil, urllib.request, zipfile, time, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from functools import wraps\n",
    "from math import trunc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from scipy.sparse.linalg import norm\n",
    "import scipy.sparse as ss\n",
    "from scipy.sparse.linalg import svds\n",
    "from tqdm import tqdm\n",
    "from numba import njit\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "SEED = 123\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mktkcXOFQrw"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "te-qO_lGEkBr"
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return mse(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lj_Na91f60Vw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserID MovieID  Rating  Timestamp\n",
       "0      1    1193       5  978300760\n",
       "1      1     661       3  978302109\n",
       "2      1     914       3  978301968\n",
       "3      1    3408       4  978300275\n",
       "4      1    2355       5  978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dataset():\n",
    "    path = Path(\"m1.zip\")\n",
    "    if not path.exists():\n",
    "        with path.open(\"wb\") as f:\n",
    "            print(\"Downloading dataset...\")\n",
    "            f.write(urlopen(\"http://files.grouplens.org/datasets/movielens/ml-1m.zip\").read())\n",
    "    if not Path(\"ml-1m\").is_dir():\n",
    "        print(\"unzipping...\")\n",
    "        with ZipFile(\"m1.zip\") as zf:\n",
    "            zf.extractall()\n",
    "    ratings_list = [i.strip().split(\"::\") for i in open('ml-1m/ratings.dat', 'r').readlines()]\n",
    "    ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = int)\n",
    "    ratings_df['Rating'] = ratings_df['Rating'].apply(pd.to_numeric)\n",
    "    return ratings_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGGKzJMNFQrz"
   },
   "source": [
    "pivot ratings_df to get user-rating matrix format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQh7Ixoyycky"
   },
   "source": [
    "# Funk-SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numba Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def _shuffle(X):\n",
    "    np.random.shuffle(X)\n",
    "    return X\n",
    "\n",
    "@njit\n",
    "def _initialization(n_users, n_items, n_factors):\n",
    "    bu = np.zeros(n_users)\n",
    "    bi = np.zeros(n_items)\n",
    "    pu = np.random.normal(0, .1, (n_users, n_factors))\n",
    "    qi = np.random.normal(0, .1, (n_items, n_factors))\n",
    "    return bu, bi, pu, qi\n",
    "\n",
    "@njit\n",
    "def _run_epoch(X, bu, bi, pu, qi, global_mean, n_factors, lr, reg):\n",
    "    for i in range(X.shape[0]):\n",
    "        user, item, rating = int(X[i, 0]), int(X[i, 1]), X[i, 2]\n",
    "\n",
    "        # Predict current rating\n",
    "        pred = global_mean + bu[user] + bi[item]\n",
    "\n",
    "        for factor in range(n_factors):\n",
    "            pred += pu[user, factor] * qi[item, factor]\n",
    "        err = rating - pred\n",
    "\n",
    "        # Update biases\n",
    "        bu[user] += lr * (err - reg * bu[user])\n",
    "        bi[item] += lr * (err - reg * bi[item])\n",
    "\n",
    "        # Update latent factors\n",
    "        for factor in range(n_factors):\n",
    "            puf = pu[user, factor]\n",
    "            qif = qi[item, factor]\n",
    "            pu[user, factor] += lr * (err * qif - reg * puf)\n",
    "            qi[item, factor] += lr * (err * puf - reg * qif)\n",
    "    return bu, bi, pu, qi\n",
    "\n",
    "@njit\n",
    "def _compute_val_metrics(X_val, bu, bi, pu, qi, global_mean, n_factors):\n",
    "    residuals = []\n",
    "    for i in range(X_val.shape[0]):\n",
    "        user, item, rating = int(X_val[i, 0]), int(X_val[i, 1]), X_val[i, 2]\n",
    "        pred = global_mean\n",
    "        if user > -1:\n",
    "            pred += bu[user]\n",
    "        if item > -1:\n",
    "            pred += bi[item]\n",
    "        if (user > -1) and (item > -1):\n",
    "            for factor in range(n_factors):\n",
    "                pred += pu[user, factor] * qi[item, factor]\n",
    "        residuals.append(rating - pred)\n",
    "    residuals = np.array(residuals)\n",
    "    loss = np.square(residuals).mean()\n",
    "    rmse = np.sqrt(loss)\n",
    "    mae = np.absolute(residuals).mean()\n",
    "    return loss, rmse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funk SVD Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    def __init__(self, lr=.005, reg=.02, n_epochs=20, n_factors=100,\n",
    "                 early_stopping=False, shuffle=False, min_delta=.001,\n",
    "                 min_rating=1, max_rating=5):\n",
    "\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "        self.n_epochs = n_epochs\n",
    "        self.n_factors = n_factors\n",
    "        self.early_stopping = early_stopping\n",
    "        self.shuffle = shuffle\n",
    "        self.min_delta = min_delta\n",
    "        self.min_rating = min_rating\n",
    "        self.max_rating = max_rating\n",
    "\n",
    "    def fit(self, X, X_val=None):\n",
    "        X = self._preprocess_data(X)\n",
    "\n",
    "        if X_val is not None:\n",
    "            X_val = self._preprocess_data(X_val, train=False, verbose=False)\n",
    "            self._init_metrics()\n",
    "        self.global_mean_ = np.mean(X[:, 2])\n",
    "        self._run_sgd(X, X_val)\n",
    "        return self\n",
    "\n",
    "    def _preprocess_data(self, X, train=True, verbose=True):\n",
    "#         print('Preprocessing data...\\n')\n",
    "        X = X.copy()\n",
    "\n",
    "        if train:  # Mappings have to be created\n",
    "            user_ids = X['UserID'].unique().tolist()\n",
    "            item_ids = X['MovieID'].unique().tolist()\n",
    "            n_users = len(user_ids)\n",
    "            n_items = len(item_ids)\n",
    "            user_idx = range(n_users)\n",
    "            item_idx = range(n_items)\n",
    "            self.user_mapping_ = dict(zip(user_ids, user_idx))\n",
    "            self.item_mapping_ = dict(zip(item_ids, item_idx))\n",
    "        X['UserID'] = X['UserID'].map(self.user_mapping_)\n",
    "        X['MovieID'] = X['MovieID'].map(self.item_mapping_)\n",
    "\n",
    "        # Tag validation set unknown users/items with -1 (enables\n",
    "        # `fast_methods._compute_val_metrics` detecting them)\n",
    "        X.fillna(-1, inplace=True)\n",
    "        \n",
    "        X['UserID'] = X['UserID'].astype(np.int32)\n",
    "        X['MovieID'] = X['MovieID'].astype(np.int32)\n",
    "        return X[['UserID', 'MovieID', 'Rating']].values\n",
    "\n",
    "    def _init_metrics(self):\n",
    "        metrics = np.zeros((self.n_epochs, 3), dtype=np.float)\n",
    "        self.metrics_ = pd.DataFrame(metrics, columns=['Loss', 'RMSE', 'MAE'])\n",
    "\n",
    "    def _run_sgd(self, X, X_val):\n",
    "        n_users = len(np.unique(X[:, 0]))\n",
    "        n_items = len(np.unique(X[:, 1]))\n",
    "        val_loss, val_rmse = '', ''\n",
    "        bu, bi, pu, qi = _initialization(n_users, n_items, self.n_factors)\n",
    "\n",
    "        # Run SGD\n",
    "        pbar = tqdm(range(self.n_epochs), desc='Epoch',\n",
    "                             ncols=110)\n",
    "        for epoch_ix in pbar:\n",
    "            pbar.set_postfix({'val_loss': val_loss, 'val_rmse': val_rmse})\n",
    "            start = self._on_epoch_begin(epoch_ix)\n",
    "\n",
    "            if self.shuffle:\n",
    "                X = _shuffle(X)\n",
    "\n",
    "            bu, bi, pu, qi = _run_epoch(X, bu, bi, pu, qi, self.global_mean_,\n",
    "                                        self.n_factors, self.lr, self.reg)\n",
    "\n",
    "            if X_val is not None:\n",
    "                self.metrics_.loc[epoch_ix, :] = _compute_val_metrics(\n",
    "                                                     X_val, bu, bi, pu, qi,\n",
    "                                                     self.global_mean_,\n",
    "                                                     self.n_factors)\n",
    "                val_loss, val_rmse = self._on_epoch_end(start,\n",
    "                                   self.metrics_.loc[epoch_ix, 'Loss'],\n",
    "                                   self.metrics_.loc[epoch_ix, 'RMSE'],\n",
    "                                   self.metrics_.loc[epoch_ix, 'MAE'])\n",
    "\n",
    "                if self.early_stopping:\n",
    "                    val_rmse = self.metrics_['RMSE'].tolist()\n",
    "                    if self._early_stopping(val_rmse, epoch_ix,\n",
    "                                            self.min_delta):\n",
    "                        break\n",
    "            else:\n",
    "                val_loss, val_rmse = self._on_epoch_end(start)\n",
    "\n",
    "        self.bu_ = bu\n",
    "        self.bi_ = bi\n",
    "        self.pu_ = pu\n",
    "        self.qi_ = qi\n",
    "\n",
    "    def predict(self, X, clip=True):\n",
    "        return [\n",
    "            self.predict_pair(u_id, i_id, clip)\n",
    "            for u_id, i_id in zip(X['UserID'], X['MovieID'])\n",
    "        ]\n",
    "\n",
    "    def predict_pair(self, u_id, i_id, clip=True):\n",
    "        user_known, item_known = False, False\n",
    "        pred = self.global_mean_\n",
    "\n",
    "        if u_id in self.user_mapping_:\n",
    "            user_known = True\n",
    "            u_ix = self.user_mapping_[u_id]\n",
    "            pred += self.bu_[u_ix]\n",
    "\n",
    "        if i_id in self.item_mapping_:\n",
    "            item_known = True\n",
    "            i_ix = self.item_mapping_[i_id]\n",
    "            pred += self.bi_[i_ix]\n",
    "\n",
    "        if user_known and item_known:\n",
    "            pred += np.dot(self.pu_[u_ix], self.qi_[i_ix])\n",
    "\n",
    "        if clip:\n",
    "            pred = self.max_rating if pred > self.max_rating else pred\n",
    "            pred = self.min_rating if pred < self.min_rating else pred\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def _early_stopping(self, val_rmse, epoch_idx, min_delta):\n",
    "        if epoch_idx > 0:\n",
    "            if val_rmse[epoch_idx] + min_delta > val_rmse[epoch_idx-1]:\n",
    "                self.metrics_ = self.metrics_.loc[:(epoch_idx+1), :]\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _on_epoch_begin(self, epoch_ix):\n",
    "        start = time.time()\n",
    "        end = '  | ' if epoch_ix < 9 else ' | '\n",
    "#         print('Epoch {}/{}'.format(epoch_ix + 1, self.n_epochs), end=end)\n",
    "\n",
    "        return start\n",
    "\n",
    "    def _on_epoch_end(self, start, val_loss=None, val_rmse=None, val_mae=None):\n",
    "        end = time.time()\n",
    "        return f'{val_loss:.3f}', f'{val_rmse:.3f}'\n",
    "#         print(f'took {end - start:.1f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "iI9441n7DltF"
   },
   "outputs": [],
   "source": [
    "ratings_df = get_dataset()\n",
    "R_df = ratings_df.pivot(index = 'UserID', columns ='MovieID', values = 'Rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "LVakVYG0rT_C"
   },
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "test_indices = np.array(random.sample(list(np.argwhere(R_df.values>0)), 2500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "-6PSReAzrbvQ",
    "outputId": "539848f5-c47e-4a7d-8558-02545f03bbc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        UserID  MovieID  Rating\n",
      "974967    1265     1732     4.0\n",
      "540199    2456     2105     3.0\n",
      "843159    1449     2959     4.0\n",
      "98506     5350     2640     2.0\n",
      "440052    3323     3468     4.0\n",
      "        UserID  MovieID  Rating\n",
      "206405    1265     1732     4.0\n",
      "409183    2456     2105     3.0\n",
      "240650    1449     2959     4.0\n",
      "886005    5350     2640     2.0\n",
      "540360    3323     3468     4.0\n",
      "True\n",
      "        UserID  MovieID  Rating\n",
      "910076       1        1     5.0\n",
      "910083       1       48     5.0\n",
      "904601       1      150     5.0\n",
      "904587       1      260     4.0\n",
      "910072       1      527     5.0\n",
      "    UserID  MovieID  Rating\n",
      "40       1        1     5.0\n",
      "25       1       48     5.0\n",
      "39       1      150     5.0\n",
      "44       1      260     4.0\n",
      "23       1      527     5.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split(df, R_df, test_indices):\n",
    "    x_indices = test_indices[:,0]\n",
    "    y_indices = test_indices[:,1]\n",
    "    u_ids = R_df.index[x_indices].astype(np.int32)\n",
    "    i_ids = R_df.columns[y_indices].astype(np.int32)\n",
    "    \n",
    "    df['UserID'] = df['UserID'].astype(np.int32)\n",
    "    df['MovieID'] = df['MovieID'].astype(np.int32)\n",
    "    df['Rating'] = df['Rating'].astype(np.float64)\n",
    "    \n",
    "    df= df.drop(columns=['Timestamp'], errors='ignore')\n",
    "    \n",
    "    test = []\n",
    "    for u_id, i_id in zip(u_ids, i_ids):\n",
    "        test.append(df.loc[(df['UserID'] == u_id) & (df['MovieID'] == i_id)])\n",
    "    test_df = pd.concat(test)\n",
    "    train_df= df.drop(test_df.index.tolist())\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = split(ratings_df, R_df, test_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(train_df.shape)\n",
    "print(train_df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cellView": "code",
    "id": "vfXchdoCr7Z5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|████████████████████████████████| 100/100 [00:07<00:00, 12.51it/s, val_loss=0.747, val_rmse=0.864]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.8627\n",
      "\n",
      "Hyperparams: \n",
      "('shuffle', False)\n",
      "('min_rating', 1)\n",
      "('max_rating', 5)\n",
      "('early_stopping', False)\n",
      "('min_delta', 1e-05)\n",
      "('lr', 0.001)\n",
      "('reg', 0.002)\n",
      "('n_epochs', 100)\n",
      "('n_factors', 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def funk(train, test, **kw):\n",
    "    hparams = '\\n'.join(map(str, kw.items()))\n",
    "    seed_everything()\n",
    "    svd = SVD(**kw)\n",
    "    svd.fit(X=train, X_val=test)\n",
    "    y_true, y_pred = test['Rating'], svd.predict(test)\n",
    "    print(f\"Test RMSE: {rmse(y_true, y_pred):.4f}\\n\\nHyperparams: \\n{hparams}\")\n",
    "\n",
    "funk(train=train_df, test=test_df,\n",
    "                shuffle=False, min_rating=1, max_rating=5, early_stopping=False,\n",
    "                min_delta=.00001,\n",
    "                lr=.001,\n",
    "                reg=.002,\n",
    "#                 n_epochs=100,\n",
    "                n_factors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training took 16 sec\n",
    "# Test RMSE: 0.8416\n",
    "\n",
    "# Hyperparams: \n",
    "# ('shuffle', False)\n",
    "# ('min_rating', 1)\n",
    "# ('max_rating', 5)\n",
    "# ('early_stopping', False)\n",
    "# ('min_delta', 1e-05)\n",
    "# ('lr', 0.0007)\n",
    "# ('reg', 0.02)\n",
    "# ('n_epochs', 300)\n",
    "# ('n_factors', 20)\n",
    "\n",
    "# Training took 20 sec\n",
    "# Test RMSE: 0.8412\n",
    "\n",
    "# Hyperparams: \n",
    "# ('shuffle', False)\n",
    "# ('min_rating', 1)\n",
    "# ('max_rating', 5)\n",
    "# ('early_stopping', True)\n",
    "# ('min_delta', 1e-05)\n",
    "# ('lr', 0.0006)\n",
    "# ('reg', 0.015)\n",
    "# ('n_epochs', 1000)\n",
    "# ('n_factors', 25)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ex3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
